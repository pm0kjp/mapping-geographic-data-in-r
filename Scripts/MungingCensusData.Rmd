---
title: "Munging Census Data"
author: "Joy Payton"
date: "2/26/2019"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r setup, include=FALSE}


# Note you may need to install some packages!
# install.packages(c("kableExtra", "tidycensus"), dependencies = TRUE)

# You will CERTAINLY need to get a census API key -- read on below.


knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = TRUE)
library(kableExtra)
```

## "Munging"

So, I thought I'd check out the use over time of the word _munging_, and I found some cool things while Googling.  I haven't gone the extra mile to figure out what 19th century "munging" refers to!

```{r echo=FALSE}
knitr::include_graphics('../Media/munging_use_over_time.png', dpi = 100)
```

Also [this](https://en.oxforddictionaries.com/definition/mung): "1960s: origin uncertain (frequently said to be an acronym from _mash until no good_)."

To be clear, here I mean by _munging_ the trial-and-error reshaping, filtering, and transformation of data to get it into a form that is useful.  It may involve "mashing", but not "until no good"!

## The United States Census Bureau

The US Census Bureau is bound by the Constitution to do a full (not sampled) census of all people within the US every ten years.  This determines the number of seats in the US House of Representatives and are used to draw district boundaries.  This is the _Decennial Census_.  There are two additional censuses performed by the Census Bureau that we won't talk about: an _Economic Census_ done every five years and the _Census of Governments_ done every five years.

In addition to the full population census, the Census Bureau is also responsible for conducting the _American Community Survey_ (ACS) which uses sampling and inferential statistics to make estimates of things like:

* Education levels
* Poverty
* Mean and median income
* Computer usage
* Crime
* and much more!

Note that the ACS also has one and five year versions.  Five year ACS data includes estimates for the entire country, while one year versions concentrate on population-dense areas and have smaller sample sizes.  This means that if you're doing analysis on, say, NYC, you can get very up-to-date (but less reliable) 1-year estimates, but if you're interested in studying Iowa, or getting NYC estimates with a smaller margin of error, you'd be better off with a somewhat less current but broader and more reliable 5 year ACS.  That's what we'll use in this script -- five year ACS estimates.

Census data is collected at and aggregated to various levels:

* The country as a whole
* States / territories
* Counties
* ZIP Code Tabulation Areas (approximations of ZIP Codes)
* Urban areas
* Census Tracts (1-8k people)
* Census Block Groups
* Census Blocks (600 - 3k people)
* and probably more I've forgotten about!

The [website of the Census Bureau](https://www.census.gov) is a veritable treasure trove of data about populations.  It can be hard to manage the sheer quantity of data.

## FIPS

"FIPS" stands for "Federal Information Processing Standards" but often, when you talk to people, they'll apply the term to whatever their particular federal data is... so, e.g., instead of "Census tract identifier" they'll say "the FIPS".  It's a term that therefore ends up having lots of meanings.

There are FIPS codes for states, counties, tracts, and blocks, and when concatenated, they end up being a single geographic id.  For example, the state code for Pennsylvania is 42, the county code for Philadelphia is 101, and the census tract within Philadelphia where the main campus of the Children's Hospital of Philadelphia stands is 036900 (the last two digits can be thought of as 'after the decimal point', so this has a "human" name of Census Tract 369).  Further, the block group is 2, and the full block number is 2011, so you might be using a "GEOID" of 421010369002011 (if the block is included), or just 42101036900 (if you have tract level data only).

## Access to Census Data

### APIs

Plan to work with Census Bureau data over and over again?  It's worth the time to use APIs.

The Census Bureau offers __free__ API credentials (and a Slack channel, and more) at their [Developers page](https://www.census.gov/developers/).  Among their [list of API endpoints](https://www.census.gov/data/developers/data-sets.html) is a geocoding service -- which is how we can translate street addresses to a geospatial point (lat/long).  You can also just do a one-off at <https://geocoding.geo.census.gov/geocoder/>.

[`tidycensus`](https://cran.r-project.org/package=tidycensus) is a package that helps you work with specific APIs offered by the Census Bureau.


### Web GUI

You can also manually choose data and download it using the American Fact Finder (<https://factfinder.census.org>).  A few asides here: 

* you will probably want to transpose rows and columns
* you will probably want to leave the optional boxes unchecked.

## Caveats

### Granularity of Data

Census data is very very specific.  If, for example, you're interested in income data for a given tract, you might find columns that include descriptions like:

* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Total households - Less than $10,000
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Total households - $10,000 to $14,999
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Total households - $15,000 to $24,999
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Total households - $25,000 to $34,999
* ... and so on ..

Or:

* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Families - Less than $10,000
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Families - $10,000 to $14,999
* ... and so on ...

Or: 

* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - With Supplemental Security Income - Mean Supplemental Security Income (dollars)
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - With cash public assistance income - Mean cash public assistance income (dollars)
* ... and so on...

Or:

* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Median earnings for workers (dollars)
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Median earnings for male full-time, year-round workers (dollars)
* INCOME AND BENEFITS (IN 2017 INFLATION-ADJUSTED DOLLARS) - Median earnings for female full-time, year-round workers (dollars)

You will likely need to do a bit of honing your question:  families only, or all households (say, a single person, or a group home)?  Do you want to look at statistics across the board or specify race, sex, or hispanicity?  What is considered income, and what benefits?  Do you want to include SSI?  Measure it separately?  What about welfare?

### Estimates and MOEs

You'll also find, for any given measure, a few variables related to it:

* Estimate -- used when a scalar count or value is needed, like median income or number of white women
* Margin of error -- used to indicate the precision of the estimate
* Percent -- used when a percent is needed, like percent of families below the poverty line
* Percent Margin of Error -- used to indicate the precision of the percent estimate

Note that all four columns are generally present although only two make sense for any given measure!

### Sparsity

Every area of the US belongs to a census tract, even if it's an area in which people don't normally live (like a park or lake or airport).  That's why you might see census tracts with little to no data.  Don't panic if you see that a few tracts have very sparse data -- they may be one of these special tracts.

## Let's Get Census Data!

### API Setup

First, I'm going to pull in my API key.  You'll want to change the line below or put a file containing your API key in the place specified below.  I've excluded the "Private" folder from being included in the GitHub repo, so you'll want to add your own on your local machine.

```{r}
census_key <- readLines("../Private/census_api_key.txt")
```

Let's use `tidycensus`!  It creates a smoother experience for a handful of Census API calls.  I'll set my census key once using `tidycensus::census_key` so that I don't have to keep referencing it in API calls I make.

```{r}
library(tidycensus)
census_api_key(census_key)
options(tigris_use_cache = TRUE)
```

### American Community Survey

#### Understanding Variables 

What variables are available, say, for the five year American Community Survey?  I need to know the end year of the survey I care about, so I can go to <https://www.census.gov/programs-surveys/acs> to discover that 2017 is the latest year end.  Scroll through the variables below ... there are a LOT.

```{r}
library(dplyr)

acs5_vars <- load_variables(2017, "acs5")
kable(acs5_vars) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```


There are `r nrow(acs5_vars)` variables that describe `r length(unique(acs5_vars$concept))` unique concepts.

Let's take a look at the concepts that are available:

```{r}
kable(unique(acs5_vars$concept)) %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

#### Using `get_acs` With Names

Maybe we want to hone in on, say, median household income for the census tracts that comprise New York City.  Specifically, I want the variable `B19113_001`.  In my use of `get_acs` I can use geographical names, like "New York", or the FIPS code for those places.  Here, to foster ease of reading, I've used the county names of the five boroughs.  

We can get just the tabular data (the data frame with information) or we can also get the geography.  While it isn't quite the same as what you'd get with `rgdal`, it's still an `sp` object type, so `leaflet` can use it for mapping.

Let's look at it both ways:

##### Just Tabular Data

```{r}
nyc_median_income <- get_acs(geography = "tract",
                             variables = "B19113_001",
                             state = "NY",
                             county = c("New York", 
                                        "Richmond", 
                                        "Queens", 
                                        "Kings", 
                                        "Bronx"),
                             survey = "acs5")

```

Let's take a peek:

```{r}
head(nyc_median_income) %>%
  kable() %>%
  kable_styling()
```

##### With Geography

```{r message = FALSE, results='hide'}
nyc_median_income_geog <- get_acs(geography = "tract",
                             variables = "B19113_001",
                             state = "NY",
                             county = c("New York", 
                                        "Richmond", 
                                        "Queens", 
                                        "Kings", 
                                        "Bronx"),
                             survey = "acs5", 
                             geometry = TRUE)
```

```{r}
head(nyc_median_income_geog)
```

Here, we don't have bounding box info, so we can't set the view, but `leaflet` can handle that for us out of the box:

```{r}
library(leaflet)
leaflet(nyc_median_income_geog) %>%
  addPolygons()
```

#### Using `get_acs` With Codes

The use of strings, like I've done here, can be very error prone.  Let's do something similar for the City of Philadelphia area using FIPS codes. I can go to <https://www.census.gov/geo/reference/ansi.html> and discover that the FIPS code for the state of Pennsylvania is 42, and the code for the county I'm interested in, Philadelphia County, is 101.

```{r}
philly_median_income <- get_acs(geography = "tract",
                             variables = "B19113_001",
                             state = 42,
                             county = 101,
                             survey = "acs5")
```

#### Peeking at our Data

There are `r nrow(nyc_median_income)` census tracts represented in `nyc_median_income` and `r nrow(philly_median_income)` in `philly_median_income`.

Let's take a peek at the New York City data frame and get some summary statistics.

```{r}
kable(summary(nyc_median_income)) %>%
  kable_styling()
```

Why are some of my rows missing data?  They could be tracts that correspond to areas like parks or rivers where there's only a transient population and there's no meaningful way to make predictions about median income.  When we map this data, we might understand more.

### Decennial Census Statistics

The decennial census is a full population data collection, and the number of available variables and geographic levels supported is reduced, when compared to the American Community Survey.

We can get available variables for the decennial census in much the same way as we did for the American Community Survey.  We're going to pull from "summary file 1", or "sf1".  For information about the "sf1" / "sf2" / "sf3" differences, see: 

* https://www.census.gov/programs-surveys/decennial-census/guidance/2000.html
* https://www.census.gov/programs-surveys/decennial-census/guidance/2010.html

```{r}
decennial_vars <- load_variables(2010, "sf1")
```

Once again, there are thousands of variables... specifically, `r nrow(decennial_vars)`.  Let's look at some major concepts related to Hispanic / Latino origin specifically:

```{r}
kable(decennial_vars %>% filter(grepl("HISPANIC", concept)))  %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

Let's see if we can figure out which columns would be most useful for us to map Hispanic/Latino populations in Philadelphia county in order to plan for new markets for a supermarket chain that features Latin American ingredients.

For now, we'll get all the ones under the concept "HISPANIC OR LATINO ORIGIN", then figure out which ones are most effective.

```{r message = FALSE, results='hide'}
hisp_lat_vars <- decennial_vars %>% 
                 filter(concept == "HISPANIC OR LATINO ORIGIN") %>% 
                 pull(name)
philly_latino <- get_decennial(geography = "tract",
                               variables = hisp_lat_vars,
                               state = 42,
                               county = 101,
                               sumfile = "sf1",
                               geometry = TRUE)
```



